<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>损失函数与正则化</title>
    <link href="/2023/08/31/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    <url>/2023/08/31/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E6%AD%A3%E5%88%99%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h1 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h1><p><strong>损失函数</strong>用来评价模型的<strong>预测值</strong>和<strong>真实值</strong>不一样的程度，损失函数越好，通常模型的性能越好。不同的模型用的损失函数一般也不一样。</p><p><strong>损失函数</strong>分为<strong>经验风险损失函数</strong>和<strong>结构风险损失函数</strong>。经验风险损失函数指预测结果和实际结果的差别，结构风险损失函数是指经验风险损失函数加上正则项。</p><p><strong>基本概念：</strong></p><p>损失函数：计算的是一个样本的误差</p><p>代价函数：是整个训练集上所有样本误差的平均</p><p>目标函数：代价函数 + 正则化项</p><p><strong>损失函数（loss function）</strong>是用来估量你模型的预测值f(x)与真实值Y的不一致程度，它是一个非负实值函数,通常使用L(Y, f(x))来表示，损失函数越小，模型的鲁棒性就越好。</p><p>损失函数是<strong>经验风险函数</strong>的核心部分，也是结构风险函数重要组成部分。</p><p>模型的<strong>结构风险函数</strong>包括了经验风险项和正则项，即最优化经验风险和结构风险，而这个函数就被称为<strong>目标函数</strong></p><h1 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h1><p><a href="https://charlesliuyx.github.io/2017/10/03/%E3%80%90%E7%9B%B4%E8%A7%82%E8%AF%A6%E8%A7%A3%E3%80%91%E4%BB%80%E4%B9%88%E6%98%AF%E6%AD%A3%E5%88%99%E5%8C%96/">【直观详解】什么是正则化 | Go Further | Stay Hungry, Stay Foolish (charlesliuyx.github.io)</a></p><p><a href="https://www.bilibili.com/video/BV1aE411o7qd/?p=11&spm_id_from=pageDriver&vd_source=cf891a3e71b6dda092ce868f3c80895c">(系列三) 线性回归3-正则化-岭回归-频率角度_哔哩哔哩_bilibili</a>（为什么正则化可以防止过拟合视频）</p><p><a href="https://zhuanlan.zhihu.com/p/581267829">为什么正则化可以防止过拟合？ - 知乎 (zhihu.com)</a></p><h2 id="为什么要有正则化"><a href="#为什么要有正则化" class="headerlink" title="为什么要有正则化"></a>为什么要有正则化</h2><p>从使用正则化的目的角度：<strong>正则化是为了防止过拟合</strong>。</p><h2 id="正则化如何实现目的"><a href="#正则化如何实现目的" class="headerlink" title="正则化如何实现目的"></a>正则化如何实现目的</h2><ul><li><p><strong>通俗地理解怎么做到这一点：</strong>向你的模型加入某些规则，加入先验，缩小解空间，减小求出错误解的可能性。你要把你的知识数学化告诉这个模型，对代价函数来说，就是加入对模型“长相”的惩罚</p></li><li><p><strong>权衡的角度理解怎么做到这一点：</strong></p><p>很多人都在讲偏差-方差的权衡（bias-variance tradeoff），实际上在这里还有一个权衡，即<strong>样本内的误差与模型（或者参数）的误差之间的权衡</strong>。模型越「大」，则样本内的误差越小，但是参数的误差可能会很大：比如在第一张图中，如果使用了太高阶的多项式，样本点的一个小小的扰动都会使得估计出的模型（参数）有非常大的变化；而<strong>模型越「小」，样本内的均方误差会大一些，但是参数的均方误差可以变的比较小。</strong></p><p>而<strong>正则化，就是通过收缩的办法，限制模型变的越来越「大」，牺牲样本内误差，降低模型（参数）的误差，从而提高样本外的预测效果</strong>，防止过拟合。</p></li></ul><h2 id="正则化的公式"><a href="#正则化的公式" class="headerlink" title="正则化的公式"></a>正则化的公式</h2><ul><li><p>p正则化其实就是在原来的损失函数后面加上一个带正则化系数的p范数</p><ul><li><p>L1正则化</p><p>J(w)&#x3D;12m∑i&#x3D;1m(hw(x(i))−y(i))2+λ∣∣w∣∣1J(w) &#x3D; \frac{1}{2m}\sum_{i&#x3D;1}^{m}(h_w(x^{(i)})-y^{(i)})^2 + \lambda||w||_1J(w)&#x3D;2m1∑i&#x3D;1m(hw(x(i))−y(i))2+λ∣∣w∣∣1</p></li><li><p>L2正则化</p><p>J(w)&#x3D;12m∑i&#x3D;1m(hw(x(i))−y(i))2+λ2∣∣w∣∣22J(w) &#x3D; \frac{1}{2m}\sum_{i&#x3D;1}^{m}(h_w(x^{(i)})-y^{(i)})^2 + \frac{\lambda}{2}||w||_2^2J(w)&#x3D;2m1∑i&#x3D;1m(hw(x(i))−y(i))2+2λ∣∣w∣∣22</p></li><li><p>正则化系数λ\lambdaλ</p><p>在正则化中，正则化系数 λ\lambdaλ 控制着正则化的强度，<strong>较大的 *<em>**λ\lambdaλ**</em>* 会导致模型更加倾向于简单的解决方案，而较小的 *<em>**λ\lambdaλ**</em>* 则会让模型更倾向于拟合训练数据。</strong></p></li></ul></li></ul><h2 id="自己的理解"><a href="#自己的理解" class="headerlink" title="自己的理解"></a>自己的理解</h2><ul><li>所以最后加上的正则化项其实衡量的就是模型输出（xix_ixi）之间的方差（L2正则化为例），所以模型越大，方差自然也就越大，也就是惩罚越多。这也是前面说的模型大模型小的含义。</li></ul><h2 id="【补充理解】范数"><a href="#【补充理解】范数" class="headerlink" title="【补充理解】范数"></a>【补充理解】范数</h2><ul><li>p范数公式</li></ul><p><img src="https://secure2.wostatic.cn/static/gunm6eRdXMA1xZXtVnKjVm/image.png?auth_key=1693486530-3tFtq8QbysyMxwsKQgbBkh-0-2c0365af4f6d7edb6eb86caf8a48d420" alt="img"></p><p><strong>0范数</strong>，向量中非零元素的个数。</p><p><strong>1范数</strong>，为绝对值之和。</p><p><strong>2范数</strong>，就是通常意义上的模。</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul><li>L1正则化可以得到稀疏解</li></ul>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>深度学习</category>
      
      <category>基础概念</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
